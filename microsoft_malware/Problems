loading of data, since daat size is large:::: since data size is large use catagorical as data type for object columns in data refer https://www.kaggle.com/shrutimechlearn/large-data-loading-trick-with-ms-malware-data
droping data with 80% or more missing value
filling statistical missing values
dropping catagorical data with more than 20 of different catagories
dropping skewed catagorical data having only 1 catagory out of all the catagories appearing for more than 95%
filling catagorcal missing values
encode all catagorical value using one- hot encoder???????
whatever processsing has been foolowed on training data put it on testing data
merge statistic data and catagorical data
select weather to use pca data or simple variables without dimention reduction.
how to select PCA n_component
Finding Outliers and resolving them using z score and box plot..
here box plot can be used for univariate data but for multivariate data need to use z score and standard threashold for z score value is 3
'''newtrain=train[(np.abs(stats.zscore(train.select_dtypes(include=np.number))) < 3).all(axis=1)]''' Function to remove outliers.
SVM has inbuilt feature to ignore outliars and find its froper plane


There's a way to optimise for the reading issue
  Load objects as categories.
  Binary values are switched to int8
  Binary values with missing values are switched to float16 (int does not understand nan)
  64 bits encoding are all switched to 32, or 16 of possible
